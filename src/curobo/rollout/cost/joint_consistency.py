from typing import List, Optional, Union
import torch
from dataclasses import dataclass
from curobo.rollout.cost.cost_base import CostConfig


@dataclass
class JointConsistencyConfig(CostConfig):
    group_allowed_diff: List[float] = None
    selected_joint_groups: List[Union[List[int], List[str]]] = None  # æ¯ç»„å…³èŠ‚åæˆ–ç´¢å¼•
    group_weight: Optional[List[float]] = None  # æ¯ç»„æƒ©ç½šæƒé‡ï¼ˆå¯é€‰ï¼‰

    def __post_init__(self):
        super().__post_init__()
        if isinstance(self.group_allowed_diff, list):
            self.group_allowed_diff = self.tensor_args.to_device(self.group_allowed_diff)
        if self.group_weight is not None and isinstance(self.group_weight, list):
            self.group_weight = self.tensor_args.to_device(self.group_weight)
        if self.weight is None:
            self.weight = self.tensor_args.to_device([1.0])


class JointConsistency:
    def __init__(
        self,
        config: JointConsistencyConfig,
        joint_name_to_index_fn: Optional[callable] = None
    ):
        self.tensor_args = getattr(config, "tensor_args", None)
        self.weight = config.weight
        self.group_allowed_diff = config.group_allowed_diff
        self.group_weight = config.group_weight
        self.selected_joint_groups = config.selected_joint_groups

        self.joint_index_to_name = None  # ç”¨äºŽ debug è¾“å‡º joint åç§°

        # joint name è½¬æ¢ä¸º indexï¼Œå¹¶å»ºç«‹è°ƒè¯•æ˜ å°„
        if joint_name_to_index_fn is not None and isinstance(self.selected_joint_groups[0][0], str):
            # æž„é€  joint name â†’ index æ˜ å°„ & index â†’ name æ˜ å°„
            name_index_pairs = [
                (name, joint_name_to_index_fn(name))
                for group in self.selected_joint_groups for name in group
            ]
            self.joint_index_to_name = {
                idx: name for name, idx in name_index_pairs
            }

            # æ›¿æ¢ selected_joint_groups ä¸º index æ ¼å¼
            self.selected_joint_groups = [
                [joint_name_to_index_fn(name) for name in group]
                for group in self.selected_joint_groups
            ]

    def forward(self, joint_state: torch.Tensor, opt_progress: float = 0.0, debug: bool = False) -> torch.Tensor:
        """
        joint_state: [B, H, DOF] - joint angle values across time horizon
        Returns:
            A cost tensor of shape [B, H], representing the joint consistency penalty.
        """
        with torch.autograd.profiler.record_function("cost/joint_consistency"):
            if debug:
                print("=== [JointConsistency Debug Info] ===")
                print("   joint_state shape:", joint_state.shape)
                print("   Mapped joint groups (indices):", self.selected_joint_groups)

            constraint_list = []
            for i, group in enumerate(self.selected_joint_groups):
                group_joints = joint_state[..., group]  # [B, H, len(group)]
                group_var = group_joints.var(dim=-1)  # [B, H]

                threshold = self.group_allowed_diff[i]
                if not isinstance(threshold, torch.Tensor):
                    threshold = torch.tensor(threshold, device=group_var.device, dtype=group_var.dtype)
                violation = torch.clamp(group_var - threshold, min=0.0)  # [B, H]

                if self.group_weight is not None:
                    weight = self.group_weight[i]
                    if not isinstance(weight, torch.Tensor):
                        weight = torch.tensor(weight, device=violation.device, dtype=violation.dtype)
                    violation = violation * weight

                if debug:
                    joint_names = None
                    if self.joint_index_to_name is not None:
                        joint_names = [self.joint_index_to_name.get(idx, f"?{idx}") for idx in group]

                    print(f"-- Group {i}: {group}")
                    if joint_names:
                        print(f"   Joint names: {joint_names}")
                    print("   Joint trajectory over time (Batch 0):")
                    for t in range(group_joints.shape[1]):
                        joint_val_t = group_joints[0, t]  # shape: [len(group)]
                        joint_val_str = ", ".join([f"{v.item():+.3f}" for v in joint_val_t])
                        print(f"     t={t:2d}: [{joint_val_str}]")

                    print(f"   Variance: {group_var[0]}")
                    print(f"   Threshold: {threshold}")
                    print(f"   Violation: {violation[0]}")

                constraint_list.append(violation)

            constraint_tensor = torch.stack(constraint_list, dim=-1).sum(dim=-1)  # [B, H]

            # ðŸŒŸ å¢žå¼ºæƒ©ç½šå¼ºåº¦ï¼šéš opt_progress å¢žé•¿ (æŒ‡æ•°åž‹)
            scale = (opt_progress + 1e-3) ** 3
            final_cost = self.weight * scale * constraint_tensor

            if debug:
                print(f">> Progress-scaled factor: {scale:.4f}")
                print(f">> Final Joint Consistency Cost (batch 0): {final_cost[0]}")

            return final_cost
